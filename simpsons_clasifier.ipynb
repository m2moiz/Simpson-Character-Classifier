{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpsons character classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import History\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "img_dim = 100 \n",
    "\n",
    "# Here the trainin data is augmented by transforming the images slightly to allow for more data variation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory('simpsons_training',\n",
    "                                              target_size=(img_dim, img_dim),\n",
    "                                              shuffle = True,\n",
    "                                              batch_size = batch_size)\n",
    "\n",
    "# The testing images are limited in that we only have 20 classes\n",
    "test_gen = test_datagen.flow_from_directory('simpsons_testing', \n",
    "                                            target_size=(img_dim, img_dim),\n",
    "                                            shuffle = True,\n",
    "                                            batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we show some of the augmented images\n",
    "plt.figure(figsize=(10,3))\n",
    "x,y = train_gen.next()\n",
    "for i in range(0,3):\n",
    "    image = x[i]\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here we can choose to save the augmented images so that we dont have to dont the training again on subsequent runs\n",
    "save_aug_imgs = False;\n",
    "if save_aug_imgs == True:\n",
    "    train_gen = train_datagen.flow_from_directory('simpsons_training',\n",
    "                                                  target_size=(img_dim, img_dim),\n",
    "                                                  shuffle = False,\n",
    "                                                  batch_size = batch_size,                                             \n",
    "                                                  save_to_dir='augmented',\n",
    "                                                  save_prefix='augmented')\n",
    "    i = 0\n",
    "    for batch in train_gen:\n",
    "        i += 1\n",
    "        if i > 10: \n",
    "            break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(img_dim, img_dim, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(47))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = History()\n",
    "\n",
    "# Train new model, else load trained model\n",
    "train_new_model = False;\n",
    "if train_new_model == True:\n",
    "    model.fit_generator(train_gen,\n",
    "                        steps_per_epoch = 20000//batch_size,\n",
    "                        epochs = 50,\n",
    "                        validation_data = test_gen,\n",
    "                        validation_steps = 1500//batch_size,\n",
    "                        callbacks=[history])\n",
    "    # Save the model and scores during training epochs\n",
    "    model.save('simpsons.h5')\n",
    "    history_df = pd.DataFrame(history.history)\n",
    "    history_df.to_csv(\"history.csv\")\n",
    "else:\n",
    "    model = keras.models.load_model('simpsons.h5')\n",
    "    history_df = pd.read_csv('history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "# Training history\n",
    "ax = plt.subplot(1,2,1)\n",
    "history_df['acc'].plot()\n",
    "history_df['val_acc'].plot()\n",
    "ax.legend(['Training accuracy','Validation accuracy'])\n",
    "ax.set_xlabel('Epoch')\n",
    "ax = plt.subplot(1,2,2)\n",
    "history_df['loss'].plot()\n",
    "history_df['val_loss'].plot()\n",
    "ax.legend(['Training loss','Validation loss']);\n",
    "ax.set_xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the image index to the predicted label\n",
    "label_inv_dict = train_gen.class_indices\n",
    "label_dict = {v: k for k, v in label_inv_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View test images and predicted labels\n",
    "plt.figure(figsize=(15,5))\n",
    "x,y = test_gen.next()\n",
    "for i in range(0,5):\n",
    "    image = x[i]\n",
    "    y_prob = model.predict(x) \n",
    "    y_class = y_prob[i].argmax(axis=-1)\n",
    "    y_label = label_dict[y_class]\n",
    "    ax = plt.subplot(1,5,i+1)\n",
    "    ax.set_title(y_label)\n",
    "    plt.imshow(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
